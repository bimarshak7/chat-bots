{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7094871,"sourceType":"datasetVersion","datasetId":4088849},{"sourceId":158845277,"sourceType":"kernelVersion"}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport pandas as pd\nfrom collections import Counter\nimport torch\nimport random\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torchtext.vocab import vocab\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nfrom timeit import default_timer as timer\nfrom tqdm import tqdm\nimport math","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-14T10:22:06.000577Z","iopub.execute_input":"2024-01-14T10:22:06.001039Z","iopub.status.idle":"2024-01-14T10:22:06.007096Z","shell.execute_reply.started":"2024-01-14T10:22:06.001011Z","shell.execute_reply":"2024-01-14T10:22:06.006151Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/amod-mental-health-counseling-conversations-data/train.csv\")\ndf.sample(5)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.033840Z","iopub.execute_input":"2024-01-14T10:22:06.034184Z","iopub.status.idle":"2024-01-14T10:22:06.210186Z","shell.execute_reply.started":"2024-01-14T10:22:06.034159Z","shell.execute_reply":"2024-01-14T10:22:06.209228Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                Context  \\\n1631  My girlfriend broke up with me five months ago...   \n3503  My daughter seemed to be developing at a norma...   \n2369  People who are parental figures in my life hav...   \n2370  That phrase makes me crazy. It happens anytime...   \n2841  Two years ago, I was separated from the milita...   \n\n                                               Response  \n1631  New York, what would it mean about you if you ...  \n3503  Hello.It sounds like you are really concerned ...  \n2369  It sounds like you have been thinking about ho...  \n2370  It's hard to say what is okay and what is not ...  \n2841  It sounds like being separated from the armed ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Context</th>\n      <th>Response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1631</th>\n      <td>My girlfriend broke up with me five months ago...</td>\n      <td>New York, what would it mean about you if you ...</td>\n    </tr>\n    <tr>\n      <th>3503</th>\n      <td>My daughter seemed to be developing at a norma...</td>\n      <td>Hello.It sounds like you are really concerned ...</td>\n    </tr>\n    <tr>\n      <th>2369</th>\n      <td>People who are parental figures in my life hav...</td>\n      <td>It sounds like you have been thinking about ho...</td>\n    </tr>\n    <tr>\n      <th>2370</th>\n      <td>That phrase makes me crazy. It happens anytime...</td>\n      <td>It's hard to say what is okay and what is not ...</td>\n    </tr>\n    <tr>\n      <th>2841</th>\n      <td>Two years ago, I was separated from the milita...</td>\n      <td>It sounds like being separated from the armed ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = df.dropna()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.211747Z","iopub.execute_input":"2024-01-14T10:22:06.212047Z","iopub.status.idle":"2024-01-14T10:22:06.219217Z","shell.execute_reply.started":"2024-01-14T10:22:06.212016Z","shell.execute_reply":"2024-01-14T10:22:06.218244Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df[\"Context\"] = df[\"Context\"].apply(lambda x: x.lower())\ndf[\"Response\"] = df[\"Response\"].apply(lambda x: x.lower())","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.220379Z","iopub.execute_input":"2024-01-14T10:22:06.220673Z","iopub.status.idle":"2024-01-14T10:22:06.272855Z","shell.execute_reply.started":"2024-01-14T10:22:06.220642Z","shell.execute_reply":"2024-01-14T10:22:06.272003Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df[\"Context\"] = df[\"Context\"].apply(lambda x: x.replace(\"\\n\",\"\"))\ndf[\"Response\"] = df[\"Response\"].apply(lambda x: x.replace(\"\\n\",\"\"))","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.274872Z","iopub.execute_input":"2024-01-14T10:22:06.275202Z","iopub.status.idle":"2024-01-14T10:22:06.287661Z","shell.execute_reply.started":"2024-01-14T10:22:06.275175Z","shell.execute_reply":"2024-01-14T10:22:06.286567Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# df[\"context_len\"] = df[\"Context\"].apply(lambda x: len(x.split()))\n# df[\"response_len\"] = df[\"Response\"].apply(lambda x: len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.288856Z","iopub.execute_input":"2024-01-14T10:22:06.289143Z","iopub.status.idle":"2024-01-14T10:22:06.298291Z","shell.execute_reply.started":"2024-01-14T10:22:06.289120Z","shell.execute_reply":"2024-01-14T10:22:06.297317Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# df = df[df[\"context_len\"]<400]\n# df = df[df[\"response_len\"]<600]","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.299473Z","iopub.execute_input":"2024-01-14T10:22:06.299788Z","iopub.status.idle":"2024-01-14T10:22:06.309276Z","shell.execute_reply.started":"2024-01-14T10:22:06.299764Z","shell.execute_reply":"2024-01-14T10:22:06.308360Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# df[[\"context_len\",\"response_len\"]].describe()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.310432Z","iopub.execute_input":"2024-01-14T10:22:06.310743Z","iopub.status.idle":"2024-01-14T10:22:06.319242Z","shell.execute_reply.started":"2024-01-14T10:22:06.310717Z","shell.execute_reply":"2024-01-14T10:22:06.318189Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"counter = Counter()\nfor i in range(len(df)):\n    row = df.iloc[i]\n    counter.update(row[\"Context\"].split())\n    counter.update(row[\"Response\"].split())","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.320499Z","iopub.execute_input":"2024-01-14T10:22:06.320789Z","iopub.status.idle":"2024-01-14T10:22:06.700993Z","shell.execute_reply.started":"2024-01-14T10:22:06.320766Z","shell.execute_reply":"2024-01-14T10:22:06.700190Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"vocab_en = vocab(counter, min_freq=5, specials=('<UNK>', '<SOS>', '<EOS>', '<PAD>'))","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.702113Z","iopub.execute_input":"2024-01-14T10:22:06.702431Z","iopub.status.idle":"2024-01-14T10:22:06.788447Z","shell.execute_reply.started":"2024-01-14T10:22:06.702405Z","shell.execute_reply":"2024-01-14T10:22:06.787312Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"vocab_en.set_default_index(vocab_en['<UNK>'])\nlen(vocab_en)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.792700Z","iopub.execute_input":"2024-01-14T10:22:06.793028Z","iopub.status.idle":"2024-01-14T10:22:06.799945Z","shell.execute_reply.started":"2024-01-14T10:22:06.792991Z","shell.execute_reply":"2024-01-14T10:22:06.798973Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"7805"},"metadata":{}}]},{"cell_type":"code","source":"df[\"Context\"] = df[\"Context\"].apply(lambda x: \"<SOS> \"+x+\" <EOS>\")\ndf[\"Response\"] = df[\"Response\"].apply(lambda x: \"<SOS> \"+x+\" <EOS>\")","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.801262Z","iopub.execute_input":"2024-01-14T10:22:06.801596Z","iopub.status.idle":"2024-01-14T10:22:06.816799Z","shell.execute_reply.started":"2024-01-14T10:22:06.801564Z","shell.execute_reply":"2024-01-14T10:22:06.815689Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"len(df.iloc[0][\"Context\"].split())","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.818158Z","iopub.execute_input":"2024-01-14T10:22:06.818558Z","iopub.status.idle":"2024-01-14T10:22:06.834426Z","shell.execute_reply.started":"2024-01-14T10:22:06.818512Z","shell.execute_reply":"2024-01-14T10:22:06.833460Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"62"},"metadata":{}}]},{"cell_type":"code","source":"vocab_en([\"hi\",\"hello\"])","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.835672Z","iopub.execute_input":"2024-01-14T10:22:06.835990Z","iopub.status.idle":"2024-01-14T10:22:06.846102Z","shell.execute_reply.started":"2024-01-14T10:22:06.835966Z","shell.execute_reply":"2024-01-14T10:22:06.845243Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[822, 1376]"},"metadata":{}}]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, df):\n        self.X = df[\"Context\"]\n        self.y = df[\"Response\"]\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        qn = self.X.iloc[idx]\n        ans = self.y.iloc[idx]\n\n        qn_indices = vocab_en(qn.split())\n\n        ans_indices = vocab_en(ans.split())\n\n        return torch.tensor(qn_indices), torch.tensor(ans_indices)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.847454Z","iopub.execute_input":"2024-01-14T10:22:06.847747Z","iopub.status.idle":"2024-01-14T10:22:06.856189Z","shell.execute_reply.started":"2024-01-14T10:22:06.847724Z","shell.execute_reply":"2024-01-14T10:22:06.855383Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"ds = MyDataset(df)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.857295Z","iopub.execute_input":"2024-01-14T10:22:06.857638Z","iopub.status.idle":"2024-01-14T10:22:06.866078Z","shell.execute_reply.started":"2024-01-14T10:22:06.857613Z","shell.execute_reply":"2024-01-14T10:22:06.865103Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_ds,test_ds = torch.utils.data.random_split(ds, [0.8, 0.2])","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.867309Z","iopub.execute_input":"2024-01-14T10:22:06.867608Z","iopub.status.idle":"2024-01-14T10:22:06.893613Z","shell.execute_reply.started":"2024-01-14T10:22:06.867585Z","shell.execute_reply":"2024-01-14T10:22:06.892774Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 1","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.894731Z","iopub.execute_input":"2024-01-14T10:22:06.895061Z","iopub.status.idle":"2024-01-14T10:22:06.899229Z","shell.execute_reply.started":"2024-01-14T10:22:06.895035Z","shell.execute_reply":"2024-01-14T10:22:06.898342Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def my_collate(batch):\n    # Extract sequences and targets\n    qns = [item[0] for item in batch]\n    ans = [item[1] for item in batch]\n    # Pad sequences\n    padded_qn = pad_sequence(qns, padding_value=vocab_en[\"<PAD>\"])\n    padded_ans = pad_sequence(ans, padding_value=vocab_en[\"<PAD>\"])\n\n    # Return padded sequences and targets\n    return padded_qn, padded_ans","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.900587Z","iopub.execute_input":"2024-01-14T10:22:06.900885Z","iopub.status.idle":"2024-01-14T10:22:06.909893Z","shell.execute_reply.started":"2024-01-14T10:22:06.900860Z","shell.execute_reply":"2024-01-14T10:22:06.908966Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\nclass PositionalEncoding(nn.Module):\n    def __init__(self,\n                 emb_size: int,\n                 dropout: float,\n                 maxlen: int = 5000):\n        super(PositionalEncoding, self).__init__()\n        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n        pos_embedding = torch.zeros((maxlen, emb_size))\n        pos_embedding[:, 0::2] = torch.sin(pos * den)\n        pos_embedding[:, 1::2] = torch.cos(pos * den)\n        pos_embedding = pos_embedding.unsqueeze(-2)\n\n        self.dropout = nn.Dropout(dropout)\n        self.register_buffer('pos_embedding', pos_embedding)\n\n    def forward(self, token_embedding):\n        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.911040Z","iopub.execute_input":"2024-01-14T10:22:06.911358Z","iopub.status.idle":"2024-01-14T10:22:06.920498Z","shell.execute_reply.started":"2024-01-14T10:22:06.911315Z","shell.execute_reply":"2024-01-14T10:22:06.919681Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\nclass TokenEmbedding(nn.Module):\n    def __init__(self, vocab_size: int, emb_size):\n        super(TokenEmbedding, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, emb_size)\n        self.emb_size = emb_size\n\n    def forward(self, tokens):\n        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.921788Z","iopub.execute_input":"2024-01-14T10:22:06.922164Z","iopub.status.idle":"2024-01-14T10:22:06.930797Z","shell.execute_reply.started":"2024-01-14T10:22:06.922131Z","shell.execute_reply":"2024-01-14T10:22:06.929899Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Seq2Seq Network\nclass Seq2SeqTransformer(nn.Module):\n    def __init__(self,\n                 num_encoder_layers: int,\n                 num_decoder_layers: int,\n                 emb_size: int,\n                 nhead: int,\n                 src_vocab_size: int,\n                 tgt_vocab_size: int,\n                 dim_feedforward: int = 512,\n                 dropout: float = 0.1):\n        super(Seq2SeqTransformer, self).__init__()\n        self.transformer = nn.Transformer(d_model=emb_size,\n                                       nhead=nhead,\n                                       num_encoder_layers=num_encoder_layers,\n                                       num_decoder_layers=num_decoder_layers,\n                                       dim_feedforward=dim_feedforward,\n                                       dropout=dropout)\n        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n        self.positional_encoding = PositionalEncoding(\n            emb_size, dropout=dropout)\n\n    def forward(self,src, trg,src_mask,tgt_mask,src_padding_mask,tgt_padding_mask,memory_key_padding_mask):\n        src_emb = self.positional_encoding(self.src_tok_emb(src))\n        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n        return self.generator(outs)\n\n    def encode(self, src, src_mask):\n        return self.transformer.encoder(self.positional_encoding(\n                            self.src_tok_emb(src)), src_mask)\n\n    def decode(self, tgt, enc_context, tgt_mask):\n        return self.transformer.decoder(self.positional_encoding(\n                          self.tgt_tok_emb(tgt)), enc_context,\n                          tgt_mask)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.932198Z","iopub.execute_input":"2024-01-14T10:22:06.932699Z","iopub.status.idle":"2024-01-14T10:22:06.947241Z","shell.execute_reply.started":"2024-01-14T10:22:06.932670Z","shell.execute_reply":"2024-01-14T10:22:06.946167Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def generate_square_subsequent_mask(sz):\n    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n    return mask\n\n\ndef create_mask(src, tgt):\n    src_seq_len = src.shape[0]\n    tgt_seq_len = tgt.shape[0]\n\n    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n\n    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.948511Z","iopub.execute_input":"2024-01-14T10:22:06.948813Z","iopub.status.idle":"2024-01-14T10:22:06.961522Z","shell.execute_reply.started":"2024-01-14T10:22:06.948788Z","shell.execute_reply":"2024-01-14T10:22:06.960656Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(0)\n\nSRC_VOCAB_SIZE = len(vocab_en)\nTGT_VOCAB_SIZE = len(vocab_en)\nEMB_SIZE = 512\nNHEAD = 8\nFFN_HID_DIM = 512\nBATCH_SIZE = 16\nNUM_ENCODER_LAYERS = 6\nNUM_DECODER_LAYERS = 6\nPAD_IDX = vocab_en[\"<PAD>\"]\nBOS_IDX = vocab_en[\"<SOS>\"]\nEOS_IDX = vocab_en[\"<EOS>\"]","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.962766Z","iopub.execute_input":"2024-01-14T10:22:06.963123Z","iopub.status.idle":"2024-01-14T10:22:06.979320Z","shell.execute_reply.started":"2024-01-14T10:22:06.963086Z","shell.execute_reply":"2024-01-14T10:22:06.978325Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:06.980880Z","iopub.execute_input":"2024-01-14T10:22:06.981209Z","iopub.status.idle":"2024-01-14T10:22:07.443981Z","shell.execute_reply.started":"2024-01-14T10:22:06.981185Z","shell.execute_reply":"2024-01-14T10:22:07.442686Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"for p in transformer.parameters():\n    if p.dim() > 1:\n        nn.init.xavier_uniform_(p)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:07.445224Z","iopub.execute_input":"2024-01-14T10:22:07.445547Z","iopub.status.idle":"2024-01-14T10:22:07.679753Z","shell.execute_reply.started":"2024-01-14T10:22:07.445520Z","shell.execute_reply":"2024-01-14T10:22:07.679012Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:07.680945Z","iopub.execute_input":"2024-01-14T10:22:07.681356Z","iopub.status.idle":"2024-01-14T10:22:07.709100Z","shell.execute_reply.started":"2024-01-14T10:22:07.681302Z","shell.execute_reply":"2024-01-14T10:22:07.708148Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"transformer = transformer.to(DEVICE)\nloss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\noptimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:07.710250Z","iopub.execute_input":"2024-01-14T10:22:07.710600Z","iopub.status.idle":"2024-01-14T10:22:07.920826Z","shell.execute_reply.started":"2024-01-14T10:22:07.710576Z","shell.execute_reply":"2024-01-14T10:22:07.919979Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model, optimizer):\n    model.train()\n    losses = 0\n    train_dataloader = DataLoader(train_ds, batch_size=BATCH_SIZE, collate_fn=my_collate)\n    pbar = tqdm(train_dataloader)\n    for src, tgt in pbar:\n        src = src.to(DEVICE)\n        tgt = tgt.to(DEVICE)\n\n        tgt_input = tgt[:-1, :]\n\n        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n\n        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n\n        optimizer.zero_grad()\n\n        tgt_out = tgt[1:, :]\n        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n        loss.backward()\n\n        optimizer.step()\n        losses += loss.item()\n\n    return losses / len(list(train_dataloader))","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:07.925964Z","iopub.execute_input":"2024-01-14T10:22:07.926364Z","iopub.status.idle":"2024-01-14T10:22:07.934041Z","shell.execute_reply.started":"2024-01-14T10:22:07.926327Z","shell.execute_reply":"2024-01-14T10:22:07.933123Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def evaluate(model):\n    model.eval()\n    losses = 0\n\n    val_dataloader = DataLoader(test_ds, batch_size=BATCH_SIZE, collate_fn=my_collate)\n    pbar = tqdm(val_dataloader)\n    for src, tgt in pbar:\n        src = src.to(DEVICE)\n        tgt = tgt.to(DEVICE)\n\n        tgt_input = tgt[:-1, :]\n\n        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n\n        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n\n        tgt_out = tgt[1:, :]\n        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n        losses += loss.item()\n\n    return losses / len(list(val_dataloader))","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:07.935496Z","iopub.execute_input":"2024-01-14T10:22:07.935790Z","iopub.status.idle":"2024-01-14T10:22:07.948494Z","shell.execute_reply.started":"2024-01-14T10:22:07.935766Z","shell.execute_reply":"2024-01-14T10:22:07.947534Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:07.949740Z","iopub.execute_input":"2024-01-14T10:22:07.950101Z","iopub.status.idle":"2024-01-14T10:22:08.109347Z","shell.execute_reply.started":"2024-01-14T10:22:07.950068Z","shell.execute_reply":"2024-01-14T10:22:08.108371Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"670"},"metadata":{}}]},{"cell_type":"code","source":"NUM_EPOCHS = 100","metadata":{"execution":{"iopub.status.busy":"2024-01-14T09:49:12.072324Z","iopub.execute_input":"2024-01-14T09:49:12.073077Z","iopub.status.idle":"2024-01-14T09:49:12.080788Z","shell.execute_reply.started":"2024-01-14T09:49:12.073044Z","shell.execute_reply":"2024-01-14T09:49:12.080082Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"for epoch in range(1, NUM_EPOCHS+1):\n    start_time = timer()\n    train_loss = train_epoch(transformer, optimizer)\n    end_time = timer()\n    val_loss = evaluate(transformer)\n    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n    torch.save(transformer.state_dict(), \"transformer.pt\")","metadata":{"execution":{"iopub.status.busy":"2024-01-13T18:03:59.227848Z","iopub.execute_input":"2024-01-13T18:03:59.228630Z","iopub.status.idle":"2024-01-13T18:21:57.657816Z","shell.execute_reply.started":"2024-01-13T18:03:59.228593Z","shell.execute_reply":"2024-01-13T18:21:57.656836Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"100%|██████████| 176/176 [00:49<00:00,  3.58it/s]\n100%|██████████| 44/44 [00:04<00:00, 10.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 1, Train loss: 2.378, Val loss: 3.531, Epoch time = 49.633s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 176/176 [00:49<00:00,  3.58it/s]\n100%|██████████| 44/44 [00:04<00:00, 10.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 2, Train loss: 2.301, Val loss: 3.494, Epoch time = 49.600s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 176/176 [00:49<00:00,  3.59it/s]\n100%|██████████| 44/44 [00:04<00:00, 10.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 3, Train loss: 2.232, Val loss: 3.456, Epoch time = 49.597s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 176/176 [00:49<00:00,  3.59it/s]\n100%|██████████| 44/44 [00:04<00:00, 10.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 4, Train loss: 2.161, Val loss: 3.425, Epoch time = 49.571s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 176/176 [00:49<00:00,  3.59it/s]\n100%|██████████| 44/44 [00:04<00:00, 10.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 5, Train loss: 2.090, Val loss: 3.400, Epoch time = 49.596s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 176/176 [00:49<00:00,  3.59it/s]\n100%|██████████| 44/44 [00:04<00:00, 10.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 6, Train loss: 2.025, Val loss: 3.358, Epoch time = 49.581s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 176/176 [00:49<00:00,  3.59it/s]\n100%|██████████| 44/44 [00:04<00:00, 10.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 7, Train loss: 1.961, Val loss: 3.323, Epoch time = 49.586s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 176/176 [00:49<00:00,  3.59it/s]\n100%|██████████| 44/44 [00:04<00:00, 10.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 8, Train loss: 1.896, Val loss: 3.288, Epoch time = 49.577s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 176/176 [00:49<00:00,  3.59it/s]\n100%|██████████| 44/44 [00:04<00:00, 10.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 9, Train loss: 1.835, Val loss: 3.251, Epoch time = 49.596s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 176/176 [00:49<00:00,  3.59it/s]\n100%|██████████| 44/44 [00:04<00:00, 10.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 10, Train loss: 1.773, Val loss: 3.213, Epoch time = 49.567s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 176/176 [00:49<00:00,  3.59it/s]\n100%|██████████| 44/44 [00:04<00:00, 10.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 11, Train loss: 1.717, Val loss: 3.181, Epoch time = 49.599s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 176/176 [00:49<00:00,  3.59it/s]\n100%|██████████| 44/44 [00:04<00:00, 10.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 12, Train loss: 1.658, Val loss: 3.143, Epoch time = 49.600s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 176/176 [00:49<00:00,  3.59it/s]\n100%|██████████| 44/44 [00:04<00:00, 10.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 13, Train loss: 1.601, Val loss: 3.111, Epoch time = 49.605s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 176/176 [00:49<00:00,  3.59it/s]\n100%|██████████| 44/44 [00:04<00:00, 10.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 14, Train loss: 1.549, Val loss: 3.080, Epoch time = 49.618s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 176/176 [00:49<00:00,  3.59it/s]\n100%|██████████| 44/44 [00:04<00:00, 10.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 15, Train loss: 1.497, Val loss: 3.058, Epoch time = 49.550s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 176/176 [00:49<00:00,  3.58it/s]\n100%|██████████| 44/44 [00:04<00:00, 10.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 16, Train loss: 1.447, Val loss: 3.031, Epoch time = 49.674s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 176/176 [00:49<00:00,  3.59it/s]\n100%|██████████| 44/44 [00:04<00:00, 10.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 17, Train loss: 1.396, Val loss: 3.006, Epoch time = 49.605s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 176/176 [00:49<00:00,  3.58it/s]\n100%|██████████| 44/44 [00:04<00:00, 10.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 18, Train loss: 1.350, Val loss: 2.966, Epoch time = 49.623s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 176/176 [00:49<00:00,  3.59it/s]\n100%|██████████| 44/44 [00:04<00:00, 10.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 19, Train loss: 1.305, Val loss: 2.941, Epoch time = 49.604s\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 176/176 [00:49<00:00,  3.59it/s]\n100%|██████████| 44/44 [00:04<00:00, 10.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 20, Train loss: 1.261, Val loss: 2.918, Epoch time = 49.589s\n","output_type":"stream"}]},{"cell_type":"code","source":"# torch.save(transformer.state_dict(), \"transformer.pt\")","metadata":{"execution":{"iopub.status.busy":"2024-01-14T09:49:24.640840Z","iopub.execute_input":"2024-01-14T09:49:24.641254Z","iopub.status.idle":"2024-01-14T09:49:24.645355Z","shell.execute_reply.started":"2024-01-14T09:49:24.641222Z","shell.execute_reply":"2024-01-14T09:49:24.644329Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:14.627156Z","iopub.execute_input":"2024-01-14T10:22:14.627767Z","iopub.status.idle":"2024-01-14T10:22:14.779937Z","shell.execute_reply.started":"2024-01-14T10:22:14.627736Z","shell.execute_reply":"2024-01-14T10:22:14.778940Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"transformer.load_state_dict(torch.load(\"/kaggle/input/mentaltransfromer/transformer.pt\"))\ntransformer = transformer.eval()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:22:15.808382Z","iopub.execute_input":"2024-01-14T10:22:15.808870Z","iopub.status.idle":"2024-01-14T10:22:17.208482Z","shell.execute_reply.started":"2024-01-14T10:22:15.808832Z","shell.execute_reply":"2024-01-14T10:22:17.207467Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"itos = vocab_en.get_itos()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:29:06.319604Z","iopub.execute_input":"2024-01-14T10:29:06.320239Z","iopub.status.idle":"2024-01-14T10:29:06.325140Z","shell.execute_reply.started":"2024-01-14T10:29:06.320207Z","shell.execute_reply":"2024-01-14T10:29:06.324155Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# function to generate output sequence using greedy algorithm\ndef greedy_decode(model, src, src_mask, max_len, start_symbol):\n    src = src.to(DEVICE)\n    src_mask = src_mask.to(DEVICE)\n\n    memory = model.encode(src, src_mask)\n    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n    for i in range(max_len-1):\n        memory = memory.to(DEVICE)\n        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n                    .type(torch.bool)).to(DEVICE)\n        out = model.decode(ys, memory, tgt_mask)\n        out = out.transpose(0, 1)\n        prob = model.generator(out[:, -1])\n        _, next_word = torch.max(prob, dim=1)\n        next_word = next_word.item()\n\n        ys = torch.cat([ys,\n                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n        if next_word == EOS_IDX:\n            break\n    return ys\n\n\n# actual function to translate input sentence into target language\ndef get_response(model, src_sentence, max_len=70, get_score=False):\n    model.eval()\n    if not get_score:\n        src = vocab_en(src_sentence.split())\n        src.insert(0,vocab_en[\"<BOS>\"])\n        src.append(vocab_en[\"<EOS>\"])\n        src = torch.tensor(src).unsqueeze(1)\n    if get_score:\n        src = src_sentence\n    num_tokens = src.shape[0]\n    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n    tgt_tokens = greedy_decode(\n        model,  src, src_mask, max_len=num_tokens + max_len, start_symbol=BOS_IDX).flatten()\n    \n    return \" \".join([itos[i] for i in tgt_tokens if i not in [0,1,2,3]])","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:29:09.162940Z","iopub.execute_input":"2024-01-14T10:29:09.163308Z","iopub.status.idle":"2024-01-14T10:29:09.175367Z","shell.execute_reply.started":"2024-01-14T10:29:09.163281Z","shell.execute_reply":"2024-01-14T10:29:09.174296Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"while True:\n    you = input(\"YOU > \")\n    if you == \"q\" or you == \"quit\":\n        break\n\n    bot = get_response(transformer, you).split()\n    print(f\"\"\"BOT > {\" \".join(bot[:30])}\n{' ' * 5}{\" \".join(bot[30:60])}\n{' ' * 5}{\" \".join(bot[60:])if len(bot)>60 else \"\"}\\n\"\"\")\nprint(f\"\\nBOT > Bye! Have a good day dear.\")","metadata":{"execution":{"iopub.status.busy":"2024-01-14T10:17:06.793426Z","iopub.execute_input":"2024-01-14T10:17:06.793789Z","iopub.status.idle":"2024-01-14T10:17:48.652971Z","shell.execute_reply.started":"2024-01-14T10:17:06.793759Z","shell.execute_reply":"2024-01-14T10:17:48.651992Z"},"trusted":true},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdin","text":"YOU >  What coping mechanisms do you recommend for managing negative thoughts\n"},{"name":"stdout","text":"BOT > i am so sorry to hear about what happened to you! what you are describing is being in a state of shock. you haven't suddenly become a sociopath - this\n     is a normal reaction to an event that is completely overwhelming. there are most likely too many feelings to get started in real mind to start with. the first approach\n     to get some trauma counseling with a therapist, i hope this helps.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"YOU >  I had a panic attack earlier. What should I do to calm down\n"},{"name":"stdout","text":"BOT > i would suggest keeping a of those days when you are having a hard time. items to write would be what were you doing before you felt this way, did\n     you eat and what, what time of day is it, how much sleep did you get that night, this can help you identify any triggers. further assessment can be made\n     by a health care professional. it does sound like you are experiencing some symptoms of anxiety.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"YOU >   Lately, I've been feeling overwhelmed by a sense of worthlessness and hopelessness. These feelings seem to come and go, but they're significantly impacting my daily life. Can you offer some words of understanding and guidance on how to cope with these challenging emotions?\n"},{"name":"stdout","text":"BOT > i am so sorry that this happened to you! i hope you have some people you find emotionally supportive around you! in your question, i understand what you are talking\n     about. sometimes when a person experiences a person experiences a person to get the question, and it is really important to know what is being able to get yourself some\n     information about sounds as an always occurs from an image and now that a changes that may mean that you are not working toward the past and a pattern of others, but it is also common response of others, they can certainly help people define the people who are learning to people\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"YOU >  quit\n"},{"name":"stdout","text":"\nBOT > Bye! Have a good day dear.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}